<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>utils.sensitivity_analysis API documentation</title>
<meta name="description" content="This file contains the SensitivityAnalyser class â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>utils.sensitivity_analysis</code></h1>
</header>
<section id="section-intro">
<p>This file contains the SensitivityAnalyser class.</p>
<p>The SensitivityAnalyser is based on the SALib library.</p>
<p><strong>author</strong> = Louis Weyland
<strong>date</strong>
= 5/05/2022</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;This file contains the SensitivityAnalyser class.

The SensitivityAnalyser is based on the SALib library.

__author__ = Louis Weyland
__date__   = 5/05/2022
&#34;&#34;&#34;
import functools
import logging
import multiprocessing
import os
import sys
from collections import OrderedDict
from typing import Any
from typing import Callable
from typing import Dict
from typing import List
from typing import Tuple
from typing import TypeVar
from typing import Union

import graph_tool.all as gt
import numpy as np
import pandas as pd
import tqdm
from config.config import ConfigParser
from SALib.analyze import sobol
from SALib.sample import saltelli
from simulators.meta_simulator import MetaSimulator
from simulators.sim_mart_vaq import SimMartVaq
from utils.tools import DirectoryFinder
from utils.tools import timestamp

logger = logging.getLogger(&#34;logger&#34;)

SA = TypeVar(&#34;SA&#34;, bound=&#34;SensitivityAnalyser&#34;)


class SensitivityAnalyser(ConfigParser):
    &#34;&#34;&#34;Performs sensitivity analysis on different models.&#34;&#34;&#34;

    def __init__(self, problem: dict = None) -&gt; None:
        &#34;&#34;&#34;Inherit from Configparser.&#34;&#34;&#34;
        super().__init__()
        if problem is None:
            self.problem = {
                &#34;num_vars&#34;: 10,
                &#34;names&#34;: [
                    &#34;delta&#34;,
                    &#34;tau&#34;,
                    &#34;gamma&#34;,
                    &#34;beta_s&#34;,
                    &#34;beta_h&#34;,
                    &#34;beta_c&#34;,
                    &#34;c_w&#34;,
                    &#34;c_c&#34;,
                    &#34;r_w&#34;,
                    &#34;r_c&#34;,
                ],
                &#34;bounds&#34;: [
                    [0, 1],
                    [0, 1],
                    [0, 1],
                    [0, 20],
                    [0, 20],
                    [0, 20],
                    [0, 100],
                    [0, 100],
                    [0, 100],
                    [0, 100],
                ],
            }
        else:
            self.problem = problem

    def save_results(func: Callable) -&gt; Any:
        &#34;&#34;&#34;Save the sensitivity analysis results.

        Acts as a wrapper and must be at the top of the class
        &#34;&#34;&#34;

        @functools.wraps(func)
        def wrapper_decorator(self: SA, *args: Tuple, **kwargs: Dict[str, Any]) -&gt; Any:
            value = func(self, *args, **kwargs)
            # Save results
            if self.args.save:
                file_name = (
                    DirectoryFinder().result_dir_data_sa
                    + func.__name__
                    + &#34;_&#34;
                    + str(kwargs[&#34;output_value&#34;])
                    + &#34;_r_&#34;
                    + str(kwargs[&#34;rounds&#34;])
                    + &#34;_n_s_&#34;
                    + str(kwargs[&#34;n_samples&#34;])
                    + &#34;_&#34;
                    + self.args.attach_meth
                    + &#34;_&#34;
                    + timestamp()
                )

                df_list = value.to_df()
                df = pd.concat([df_list[0], df_list[1], df_list[2]], axis=1)
                with open(file_name, &#34;w&#34;) as fo:
                    fo.write(df.to_string())

            return value

        return wrapper_decorator

    @save_results
    def sim_mart_vaq_sa(
        self,
        output_value: str,
        n_samples: int,
        rounds: int,
    ) -&gt; Union[int, Dict[str, List[float]]]:
        &#34;&#34;&#34;Runnning the sensitivity analysis.&#34;&#34;&#34;
        if self.args.running_chunk:
            # chuck the sensitivity analysis and save the dataframe inbetween
            self.check_file_and_graph_exist(n_samples, rounds)
            param_values, gt_network = self.load_file_and_graph(n_samples, rounds)
            # Getting all param_values that haven&#39;t run yet
            latest_param_values = param_values[param_values.isnull().any(axis=1)]

            if len(latest_param_values) == 0:
                sys.exit(0)
            else:
                for sub_pd in self.chunker(latest_param_values, 50):
                    latest_param_values_to_list = sub_pd.values.tolist()
                    list_of_param_comb = [
                        (gt_network, self.problem, params, output_value, rounds)
                        for params in latest_param_values_to_list
                    ]

                    y = self.sensitivity_analysis_parallel(list_of_param_comb)
                    param_values.loc[sub_pd.index, &#34;y&#34;] = y
                    self.overwrite_file(param_values, n_samples, rounds)

            # analyse
            sobol_indices = sobol.analyze(self.problem, np.asarray(param_values[&#34;y&#34;]))
            return sobol_indices

        elif not self.args.running_chunk:
            # Get the network of criminal first
            meta_sim = MetaSimulator(
                network_name=self.args.read_data,
                attachment_method=self.args.attach_meth,
                ratio_honest=self.args.ratio_honest,
                ratio_wolf=self.args.ratio_wolf,
                k=self.args.k,
            )
            gt_network = meta_sim.network
            param_values = self.create_saltelli_samples(self.problem, n_samples)
            param_values = [
                (gt_network, self.problem, params, output_value, rounds)
                for params in param_values
            ]

            results = self.sensitivity_analysis_parallel(param_values)

            # analyse
            sobol_indices = sobol.analyze(self.problem, results)
            return sobol_indices
        return -1

    def sensitivity_analysis_parallel(self, list_of_param_comb: list) -&gt; np.ndarray:
        &#34;&#34;&#34;Run the simulation parallel.&#34;&#34;&#34;
        # ((number of loops*rounds/average_time_per_round)/n_threads)/ convert_to_hours
        # Running multiprocessing
        num_cpus = multiprocessing.cpu_count() - 1
        Y = []
        with multiprocessing.Pool(num_cpus) as p:
            for result in tqdm.tqdm(
                p.imap(self.sim_mart_vaq_sa_helper, list_of_param_comb),
                total=len(list_of_param_comb),
            ):
                Y.append(result)
            p.close()
            p.join()

        Y_array = np.asarray(Y)
        return Y_array

    def sim_mart_vaq_sa_helper(self, tuple_of_variable: Any) -&gt; float:
        &#34;&#34;&#34;Run the simulation Mart-Vaq given the parameter.&#34;&#34;&#34;
        # Set the seed each time, otherwise the simulation will be exactly the same
        np.random.seed(0)
        (gt_network, problem, params, output_value, rounds) = tuple_of_variable

        # Unpack input variables
        variable_dict = OrderedDict().fromkeys(problem[&#34;names&#34;], 0)
        variable_dict = dict(zip(variable_dict.keys(), params))

        simulator = SimMartVaq(network=gt_network, **variable_dict)
        _, data_collector = simulator.play(
            # ith_collect == rounds to collect only at the end
            network=simulator.network,
            rounds=rounds,
            ith_collect=rounds,
        )
        return data_collector[output_value][-1]

    def create_saltelli_samples(self, problem: dict, n_samples: int) -&gt; np.ndarray:
        &#34;&#34;&#34;Return saltelli samples.&#34;&#34;&#34;
        return saltelli.sample(problem, n_samples)

    def check_file_and_graph_exist(self, n_samples: int, rounds: int) -&gt; None:
        &#34;&#34;&#34;Check if file and graph doesn&#39;t exist otherwise create.&#34;&#34;&#34;
        file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + &#34;_&#34;
            + str(rounds)
            + &#34;_&#34;
            + str(n_samples)
            + &#34;.csv&#34;
        )
        graph_file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + f&#34;_h_{self.args.ratio_honest:.2f}_w_{self.args.ratio_wolf}_k_{self.args.k}&#34;
            + &#34;_graph.xml.gz&#34;
        )
        if not os.path.isfile(file):
            param_values = self.create_saltelli_samples(self.problem, n_samples)
            param_values = pd.DataFrame.from_records(
                param_values, columns=self.problem[&#34;names&#34;]
            )
            param_values[&#34;y&#34;] = np.nan
            param_values.to_csv(file, index=False)
        if not os.path.isfile(graph_file):
            # create graph
            meta_sim = MetaSimulator(
                network_name=self.args.read_data,
                attachment_method=self.args.attach_meth,
                ratio_honest=self.args.ratio_honest,
                ratio_wolf=self.args.ratio_wolf,
                k=self.args.k,
            )

            meta_sim.network.save(graph_file)

    def overwrite_file(
        self, param_values: pd.DataFrame, n_samples: int, rounds: int
    ) -&gt; None:
        &#34;&#34;&#34;Overwite the file with new results.&#34;&#34;&#34;
        file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + &#34;_&#34;
            + str(rounds)
            + &#34;_&#34;
            + str(n_samples)
            + &#34;.csv&#34;
        )
        param_values.to_csv(file, index=False)

    def load_file_and_graph(
        self, n_samples: int, rounds: int
    ) -&gt; Tuple[pd.DataFrame, gt.Graph]:
        &#34;&#34;&#34;Load the data and the graph.&#34;&#34;&#34;
        file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + &#34;_&#34;
            + str(rounds)
            + &#34;_&#34;
            + str(n_samples)
            + &#34;.csv&#34;
        )
        graph_file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + f&#34;_h_{self.args.ratio_honest:.2f}_w_{self.args.ratio_wolf}_k_{self.args.k}&#34;
            + &#34;_graph.xml.gz&#34;
        )
        param_values = pd.read_csv(file)
        graph = gt.load_graph(graph_file)
        return param_values, graph

    def chunker(self, seq: pd.DataFrame, size: int) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Chucks the panda DataFrame.&#34;&#34;&#34;
        return (seq[pos : pos + size] for pos in range(0, len(seq), size))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser"><code class="flex name class">
<span>class <span class="ident">SensitivityAnalyser</span></span>
<span>(</span><span>problem:Â dictÂ =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Performs sensitivity analysis on different models.</p>
<p>Inherit from Configparser.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SensitivityAnalyser(ConfigParser):
    &#34;&#34;&#34;Performs sensitivity analysis on different models.&#34;&#34;&#34;

    def __init__(self, problem: dict = None) -&gt; None:
        &#34;&#34;&#34;Inherit from Configparser.&#34;&#34;&#34;
        super().__init__()
        if problem is None:
            self.problem = {
                &#34;num_vars&#34;: 10,
                &#34;names&#34;: [
                    &#34;delta&#34;,
                    &#34;tau&#34;,
                    &#34;gamma&#34;,
                    &#34;beta_s&#34;,
                    &#34;beta_h&#34;,
                    &#34;beta_c&#34;,
                    &#34;c_w&#34;,
                    &#34;c_c&#34;,
                    &#34;r_w&#34;,
                    &#34;r_c&#34;,
                ],
                &#34;bounds&#34;: [
                    [0, 1],
                    [0, 1],
                    [0, 1],
                    [0, 20],
                    [0, 20],
                    [0, 20],
                    [0, 100],
                    [0, 100],
                    [0, 100],
                    [0, 100],
                ],
            }
        else:
            self.problem = problem

    def save_results(func: Callable) -&gt; Any:
        &#34;&#34;&#34;Save the sensitivity analysis results.

        Acts as a wrapper and must be at the top of the class
        &#34;&#34;&#34;

        @functools.wraps(func)
        def wrapper_decorator(self: SA, *args: Tuple, **kwargs: Dict[str, Any]) -&gt; Any:
            value = func(self, *args, **kwargs)
            # Save results
            if self.args.save:
                file_name = (
                    DirectoryFinder().result_dir_data_sa
                    + func.__name__
                    + &#34;_&#34;
                    + str(kwargs[&#34;output_value&#34;])
                    + &#34;_r_&#34;
                    + str(kwargs[&#34;rounds&#34;])
                    + &#34;_n_s_&#34;
                    + str(kwargs[&#34;n_samples&#34;])
                    + &#34;_&#34;
                    + self.args.attach_meth
                    + &#34;_&#34;
                    + timestamp()
                )

                df_list = value.to_df()
                df = pd.concat([df_list[0], df_list[1], df_list[2]], axis=1)
                with open(file_name, &#34;w&#34;) as fo:
                    fo.write(df.to_string())

            return value

        return wrapper_decorator

    @save_results
    def sim_mart_vaq_sa(
        self,
        output_value: str,
        n_samples: int,
        rounds: int,
    ) -&gt; Union[int, Dict[str, List[float]]]:
        &#34;&#34;&#34;Runnning the sensitivity analysis.&#34;&#34;&#34;
        if self.args.running_chunk:
            # chuck the sensitivity analysis and save the dataframe inbetween
            self.check_file_and_graph_exist(n_samples, rounds)
            param_values, gt_network = self.load_file_and_graph(n_samples, rounds)
            # Getting all param_values that haven&#39;t run yet
            latest_param_values = param_values[param_values.isnull().any(axis=1)]

            if len(latest_param_values) == 0:
                sys.exit(0)
            else:
                for sub_pd in self.chunker(latest_param_values, 50):
                    latest_param_values_to_list = sub_pd.values.tolist()
                    list_of_param_comb = [
                        (gt_network, self.problem, params, output_value, rounds)
                        for params in latest_param_values_to_list
                    ]

                    y = self.sensitivity_analysis_parallel(list_of_param_comb)
                    param_values.loc[sub_pd.index, &#34;y&#34;] = y
                    self.overwrite_file(param_values, n_samples, rounds)

            # analyse
            sobol_indices = sobol.analyze(self.problem, np.asarray(param_values[&#34;y&#34;]))
            return sobol_indices

        elif not self.args.running_chunk:
            # Get the network of criminal first
            meta_sim = MetaSimulator(
                network_name=self.args.read_data,
                attachment_method=self.args.attach_meth,
                ratio_honest=self.args.ratio_honest,
                ratio_wolf=self.args.ratio_wolf,
                k=self.args.k,
            )
            gt_network = meta_sim.network
            param_values = self.create_saltelli_samples(self.problem, n_samples)
            param_values = [
                (gt_network, self.problem, params, output_value, rounds)
                for params in param_values
            ]

            results = self.sensitivity_analysis_parallel(param_values)

            # analyse
            sobol_indices = sobol.analyze(self.problem, results)
            return sobol_indices
        return -1

    def sensitivity_analysis_parallel(self, list_of_param_comb: list) -&gt; np.ndarray:
        &#34;&#34;&#34;Run the simulation parallel.&#34;&#34;&#34;
        # ((number of loops*rounds/average_time_per_round)/n_threads)/ convert_to_hours
        # Running multiprocessing
        num_cpus = multiprocessing.cpu_count() - 1
        Y = []
        with multiprocessing.Pool(num_cpus) as p:
            for result in tqdm.tqdm(
                p.imap(self.sim_mart_vaq_sa_helper, list_of_param_comb),
                total=len(list_of_param_comb),
            ):
                Y.append(result)
            p.close()
            p.join()

        Y_array = np.asarray(Y)
        return Y_array

    def sim_mart_vaq_sa_helper(self, tuple_of_variable: Any) -&gt; float:
        &#34;&#34;&#34;Run the simulation Mart-Vaq given the parameter.&#34;&#34;&#34;
        # Set the seed each time, otherwise the simulation will be exactly the same
        np.random.seed(0)
        (gt_network, problem, params, output_value, rounds) = tuple_of_variable

        # Unpack input variables
        variable_dict = OrderedDict().fromkeys(problem[&#34;names&#34;], 0)
        variable_dict = dict(zip(variable_dict.keys(), params))

        simulator = SimMartVaq(network=gt_network, **variable_dict)
        _, data_collector = simulator.play(
            # ith_collect == rounds to collect only at the end
            network=simulator.network,
            rounds=rounds,
            ith_collect=rounds,
        )
        return data_collector[output_value][-1]

    def create_saltelli_samples(self, problem: dict, n_samples: int) -&gt; np.ndarray:
        &#34;&#34;&#34;Return saltelli samples.&#34;&#34;&#34;
        return saltelli.sample(problem, n_samples)

    def check_file_and_graph_exist(self, n_samples: int, rounds: int) -&gt; None:
        &#34;&#34;&#34;Check if file and graph doesn&#39;t exist otherwise create.&#34;&#34;&#34;
        file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + &#34;_&#34;
            + str(rounds)
            + &#34;_&#34;
            + str(n_samples)
            + &#34;.csv&#34;
        )
        graph_file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + f&#34;_h_{self.args.ratio_honest:.2f}_w_{self.args.ratio_wolf}_k_{self.args.k}&#34;
            + &#34;_graph.xml.gz&#34;
        )
        if not os.path.isfile(file):
            param_values = self.create_saltelli_samples(self.problem, n_samples)
            param_values = pd.DataFrame.from_records(
                param_values, columns=self.problem[&#34;names&#34;]
            )
            param_values[&#34;y&#34;] = np.nan
            param_values.to_csv(file, index=False)
        if not os.path.isfile(graph_file):
            # create graph
            meta_sim = MetaSimulator(
                network_name=self.args.read_data,
                attachment_method=self.args.attach_meth,
                ratio_honest=self.args.ratio_honest,
                ratio_wolf=self.args.ratio_wolf,
                k=self.args.k,
            )

            meta_sim.network.save(graph_file)

    def overwrite_file(
        self, param_values: pd.DataFrame, n_samples: int, rounds: int
    ) -&gt; None:
        &#34;&#34;&#34;Overwite the file with new results.&#34;&#34;&#34;
        file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + &#34;_&#34;
            + str(rounds)
            + &#34;_&#34;
            + str(n_samples)
            + &#34;.csv&#34;
        )
        param_values.to_csv(file, index=False)

    def load_file_and_graph(
        self, n_samples: int, rounds: int
    ) -&gt; Tuple[pd.DataFrame, gt.Graph]:
        &#34;&#34;&#34;Load the data and the graph.&#34;&#34;&#34;
        file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + &#34;_&#34;
            + str(rounds)
            + &#34;_&#34;
            + str(n_samples)
            + &#34;.csv&#34;
        )
        graph_file = (
            DirectoryFinder().result_dir_data_sa
            + self.args.attach_meth
            + f&#34;_h_{self.args.ratio_honest:.2f}_w_{self.args.ratio_wolf}_k_{self.args.k}&#34;
            + &#34;_graph.xml.gz&#34;
        )
        param_values = pd.read_csv(file)
        graph = gt.load_graph(graph_file)
        return param_values, graph

    def chunker(self, seq: pd.DataFrame, size: int) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Chucks the panda DataFrame.&#34;&#34;&#34;
        return (seq[pos : pos + size] for pos in range(0, len(seq), size))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>config.config.ConfigParser</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser.check_file_and_graph_exist"><code class="name flex">
<span>def <span class="ident">check_file_and_graph_exist</span></span>(<span>self, n_samples:Â int, rounds:Â int) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Check if file and graph doesn't exist otherwise create.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_file_and_graph_exist(self, n_samples: int, rounds: int) -&gt; None:
    &#34;&#34;&#34;Check if file and graph doesn&#39;t exist otherwise create.&#34;&#34;&#34;
    file = (
        DirectoryFinder().result_dir_data_sa
        + self.args.attach_meth
        + &#34;_&#34;
        + str(rounds)
        + &#34;_&#34;
        + str(n_samples)
        + &#34;.csv&#34;
    )
    graph_file = (
        DirectoryFinder().result_dir_data_sa
        + self.args.attach_meth
        + f&#34;_h_{self.args.ratio_honest:.2f}_w_{self.args.ratio_wolf}_k_{self.args.k}&#34;
        + &#34;_graph.xml.gz&#34;
    )
    if not os.path.isfile(file):
        param_values = self.create_saltelli_samples(self.problem, n_samples)
        param_values = pd.DataFrame.from_records(
            param_values, columns=self.problem[&#34;names&#34;]
        )
        param_values[&#34;y&#34;] = np.nan
        param_values.to_csv(file, index=False)
    if not os.path.isfile(graph_file):
        # create graph
        meta_sim = MetaSimulator(
            network_name=self.args.read_data,
            attachment_method=self.args.attach_meth,
            ratio_honest=self.args.ratio_honest,
            ratio_wolf=self.args.ratio_wolf,
            k=self.args.k,
        )

        meta_sim.network.save(graph_file)</code></pre>
</details>
</dd>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser.chunker"><code class="name flex">
<span>def <span class="ident">chunker</span></span>(<span>self, seq:Â pandas.core.frame.DataFrame, size:Â int) â€‘>Â pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Chucks the panda DataFrame.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chunker(self, seq: pd.DataFrame, size: int) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Chucks the panda DataFrame.&#34;&#34;&#34;
    return (seq[pos : pos + size] for pos in range(0, len(seq), size))</code></pre>
</details>
</dd>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser.create_saltelli_samples"><code class="name flex">
<span>def <span class="ident">create_saltelli_samples</span></span>(<span>self, problem:Â dict, n_samples:Â int) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Return saltelli samples.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_saltelli_samples(self, problem: dict, n_samples: int) -&gt; np.ndarray:
    &#34;&#34;&#34;Return saltelli samples.&#34;&#34;&#34;
    return saltelli.sample(problem, n_samples)</code></pre>
</details>
</dd>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser.load_file_and_graph"><code class="name flex">
<span>def <span class="ident">load_file_and_graph</span></span>(<span>self, n_samples:Â int, rounds:Â int) â€‘>Â Tuple[pandas.core.frame.DataFrame,Â graph_tool.Graph]</span>
</code></dt>
<dd>
<div class="desc"><p>Load the data and the graph.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_file_and_graph(
    self, n_samples: int, rounds: int
) -&gt; Tuple[pd.DataFrame, gt.Graph]:
    &#34;&#34;&#34;Load the data and the graph.&#34;&#34;&#34;
    file = (
        DirectoryFinder().result_dir_data_sa
        + self.args.attach_meth
        + &#34;_&#34;
        + str(rounds)
        + &#34;_&#34;
        + str(n_samples)
        + &#34;.csv&#34;
    )
    graph_file = (
        DirectoryFinder().result_dir_data_sa
        + self.args.attach_meth
        + f&#34;_h_{self.args.ratio_honest:.2f}_w_{self.args.ratio_wolf}_k_{self.args.k}&#34;
        + &#34;_graph.xml.gz&#34;
    )
    param_values = pd.read_csv(file)
    graph = gt.load_graph(graph_file)
    return param_values, graph</code></pre>
</details>
</dd>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser.overwrite_file"><code class="name flex">
<span>def <span class="ident">overwrite_file</span></span>(<span>self, param_values:Â pandas.core.frame.DataFrame, n_samples:Â int, rounds:Â int) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Overwite the file with new results.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def overwrite_file(
    self, param_values: pd.DataFrame, n_samples: int, rounds: int
) -&gt; None:
    &#34;&#34;&#34;Overwite the file with new results.&#34;&#34;&#34;
    file = (
        DirectoryFinder().result_dir_data_sa
        + self.args.attach_meth
        + &#34;_&#34;
        + str(rounds)
        + &#34;_&#34;
        + str(n_samples)
        + &#34;.csv&#34;
    )
    param_values.to_csv(file, index=False)</code></pre>
</details>
</dd>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser.save_results"><code class="name flex">
<span>def <span class="ident">save_results</span></span>(<span>func:Â Callable) â€‘>Â Any</span>
</code></dt>
<dd>
<div class="desc"><p>Save the sensitivity analysis results.</p>
<p>Acts as a wrapper and must be at the top of the class</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_results(func: Callable) -&gt; Any:
    &#34;&#34;&#34;Save the sensitivity analysis results.

    Acts as a wrapper and must be at the top of the class
    &#34;&#34;&#34;

    @functools.wraps(func)
    def wrapper_decorator(self: SA, *args: Tuple, **kwargs: Dict[str, Any]) -&gt; Any:
        value = func(self, *args, **kwargs)
        # Save results
        if self.args.save:
            file_name = (
                DirectoryFinder().result_dir_data_sa
                + func.__name__
                + &#34;_&#34;
                + str(kwargs[&#34;output_value&#34;])
                + &#34;_r_&#34;
                + str(kwargs[&#34;rounds&#34;])
                + &#34;_n_s_&#34;
                + str(kwargs[&#34;n_samples&#34;])
                + &#34;_&#34;
                + self.args.attach_meth
                + &#34;_&#34;
                + timestamp()
            )

            df_list = value.to_df()
            df = pd.concat([df_list[0], df_list[1], df_list[2]], axis=1)
            with open(file_name, &#34;w&#34;) as fo:
                fo.write(df.to_string())

        return value

    return wrapper_decorator</code></pre>
</details>
</dd>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser.sensitivity_analysis_parallel"><code class="name flex">
<span>def <span class="ident">sensitivity_analysis_parallel</span></span>(<span>self, list_of_param_comb:Â list) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Run the simulation parallel.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sensitivity_analysis_parallel(self, list_of_param_comb: list) -&gt; np.ndarray:
    &#34;&#34;&#34;Run the simulation parallel.&#34;&#34;&#34;
    # ((number of loops*rounds/average_time_per_round)/n_threads)/ convert_to_hours
    # Running multiprocessing
    num_cpus = multiprocessing.cpu_count() - 1
    Y = []
    with multiprocessing.Pool(num_cpus) as p:
        for result in tqdm.tqdm(
            p.imap(self.sim_mart_vaq_sa_helper, list_of_param_comb),
            total=len(list_of_param_comb),
        ):
            Y.append(result)
        p.close()
        p.join()

    Y_array = np.asarray(Y)
    return Y_array</code></pre>
</details>
</dd>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser.sim_mart_vaq_sa"><code class="name flex">
<span>def <span class="ident">sim_mart_vaq_sa</span></span>(<span>self, output_value:Â str, n_samples:Â int, rounds:Â int) â€‘>Â Union[int,Â Dict[str,Â List[float]]]</span>
</code></dt>
<dd>
<div class="desc"><p>Runnning the sensitivity analysis.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@save_results
def sim_mart_vaq_sa(
    self,
    output_value: str,
    n_samples: int,
    rounds: int,
) -&gt; Union[int, Dict[str, List[float]]]:
    &#34;&#34;&#34;Runnning the sensitivity analysis.&#34;&#34;&#34;
    if self.args.running_chunk:
        # chuck the sensitivity analysis and save the dataframe inbetween
        self.check_file_and_graph_exist(n_samples, rounds)
        param_values, gt_network = self.load_file_and_graph(n_samples, rounds)
        # Getting all param_values that haven&#39;t run yet
        latest_param_values = param_values[param_values.isnull().any(axis=1)]

        if len(latest_param_values) == 0:
            sys.exit(0)
        else:
            for sub_pd in self.chunker(latest_param_values, 50):
                latest_param_values_to_list = sub_pd.values.tolist()
                list_of_param_comb = [
                    (gt_network, self.problem, params, output_value, rounds)
                    for params in latest_param_values_to_list
                ]

                y = self.sensitivity_analysis_parallel(list_of_param_comb)
                param_values.loc[sub_pd.index, &#34;y&#34;] = y
                self.overwrite_file(param_values, n_samples, rounds)

        # analyse
        sobol_indices = sobol.analyze(self.problem, np.asarray(param_values[&#34;y&#34;]))
        return sobol_indices

    elif not self.args.running_chunk:
        # Get the network of criminal first
        meta_sim = MetaSimulator(
            network_name=self.args.read_data,
            attachment_method=self.args.attach_meth,
            ratio_honest=self.args.ratio_honest,
            ratio_wolf=self.args.ratio_wolf,
            k=self.args.k,
        )
        gt_network = meta_sim.network
        param_values = self.create_saltelli_samples(self.problem, n_samples)
        param_values = [
            (gt_network, self.problem, params, output_value, rounds)
            for params in param_values
        ]

        results = self.sensitivity_analysis_parallel(param_values)

        # analyse
        sobol_indices = sobol.analyze(self.problem, results)
        return sobol_indices
    return -1</code></pre>
</details>
</dd>
<dt id="utils.sensitivity_analysis.SensitivityAnalyser.sim_mart_vaq_sa_helper"><code class="name flex">
<span>def <span class="ident">sim_mart_vaq_sa_helper</span></span>(<span>self, tuple_of_variable:Â Any) â€‘>Â float</span>
</code></dt>
<dd>
<div class="desc"><p>Run the simulation Mart-Vaq given the parameter.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sim_mart_vaq_sa_helper(self, tuple_of_variable: Any) -&gt; float:
    &#34;&#34;&#34;Run the simulation Mart-Vaq given the parameter.&#34;&#34;&#34;
    # Set the seed each time, otherwise the simulation will be exactly the same
    np.random.seed(0)
    (gt_network, problem, params, output_value, rounds) = tuple_of_variable

    # Unpack input variables
    variable_dict = OrderedDict().fromkeys(problem[&#34;names&#34;], 0)
    variable_dict = dict(zip(variable_dict.keys(), params))

    simulator = SimMartVaq(network=gt_network, **variable_dict)
    _, data_collector = simulator.play(
        # ith_collect == rounds to collect only at the end
        network=simulator.network,
        rounds=rounds,
        ith_collect=rounds,
    )
    return data_collector[output_value][-1]</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="utils" href="index.html">utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="utils.sensitivity_analysis.SensitivityAnalyser" href="#utils.sensitivity_analysis.SensitivityAnalyser">SensitivityAnalyser</a></code></h4>
<ul class="">
<li><code><a title="utils.sensitivity_analysis.SensitivityAnalyser.check_file_and_graph_exist" href="#utils.sensitivity_analysis.SensitivityAnalyser.check_file_and_graph_exist">check_file_and_graph_exist</a></code></li>
<li><code><a title="utils.sensitivity_analysis.SensitivityAnalyser.chunker" href="#utils.sensitivity_analysis.SensitivityAnalyser.chunker">chunker</a></code></li>
<li><code><a title="utils.sensitivity_analysis.SensitivityAnalyser.create_saltelli_samples" href="#utils.sensitivity_analysis.SensitivityAnalyser.create_saltelli_samples">create_saltelli_samples</a></code></li>
<li><code><a title="utils.sensitivity_analysis.SensitivityAnalyser.load_file_and_graph" href="#utils.sensitivity_analysis.SensitivityAnalyser.load_file_and_graph">load_file_and_graph</a></code></li>
<li><code><a title="utils.sensitivity_analysis.SensitivityAnalyser.overwrite_file" href="#utils.sensitivity_analysis.SensitivityAnalyser.overwrite_file">overwrite_file</a></code></li>
<li><code><a title="utils.sensitivity_analysis.SensitivityAnalyser.save_results" href="#utils.sensitivity_analysis.SensitivityAnalyser.save_results">save_results</a></code></li>
<li><code><a title="utils.sensitivity_analysis.SensitivityAnalyser.sensitivity_analysis_parallel" href="#utils.sensitivity_analysis.SensitivityAnalyser.sensitivity_analysis_parallel">sensitivity_analysis_parallel</a></code></li>
<li><code><a title="utils.sensitivity_analysis.SensitivityAnalyser.sim_mart_vaq_sa" href="#utils.sensitivity_analysis.SensitivityAnalyser.sim_mart_vaq_sa">sim_mart_vaq_sa</a></code></li>
<li><code><a title="utils.sensitivity_analysis.SensitivityAnalyser.sim_mart_vaq_sa_helper" href="#utils.sensitivity_analysis.SensitivityAnalyser.sim_mart_vaq_sa_helper">sim_mart_vaq_sa_helper</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>
