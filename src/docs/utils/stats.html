<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>utils.stats API documentation</title>
<meta name="description" content="This script contains all the functions for performing some statistics â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>utils.stats</code></h1>
</header>
<section id="section-intro">
<p>This script contains all the functions for performing some statistics.</p>
<p><strong>author</strong> = Louis Weyland
<strong>date</strong> = 10/09/2022</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;This script contains all the functions for performing some statistics.

__author__ = Louis Weyland
__date__ = 10/09/2022
&#34;&#34;&#34;
import itertools
from copy import deepcopy
from typing import Any
from typing import DefaultDict
from typing import Dict
from typing import List
from typing import Union

import numpy as np
import pandas as pd
import similaritymeasures
from scipy import stats
from scipy.stats import pearsonr
from statsmodels.stats.multicomp import pairwise_tukeyhsd


def get_mean_std_over_list(
    data_collector: DefaultDict,
) -&gt; DefaultDict[str, Union[DefaultDict, List[Any]]]:
    &#34;&#34;&#34;Take the average and st/sem over multiple lists from a defaultdict(list).

    Args:
        data_collector (DefaultDict): Contains all the data,each main key respresent the
                                        repetition number. In other words, the data is
                                        averaged over all the repetition.

    Returns:
        DefaultDict[Union[int, str], Union[DefaultDict, List[Any]]]:
                            Returns next to the data also the mean and float for each data
    &#34;&#34;&#34;
    try:
        for k in data_collector.keys():
            if k.isalpha():
                raise RuntimeError(
                    &#34;Sorry, only numeric keys allowed, for example: round &#39;0&#39;,&#39;1&#39;,&#39;2&#39;,...&#34;
                )
    except RuntimeError:
        print(&#34;Wrong keys were given to the function.&#34;)
        raise

    repetition = len([s for s in data_collector.keys() if s.isdigit()])
    keys = list(data_collector[&#34;0&#34;].keys())
    if &#34;df&#34; in keys:
        keys.remove(&#34;df&#34;)
    for key in keys:
        m = np.zeros((repetition, len(data_collector[&#34;0&#34;][key])))
        for i in range(0, repetition):
            # Matrix repetition x rounds
            m[i, :] = data_collector[str(i)][key]
        # Get mean and std
        data_collector[&#34;mean_&#34; + key] = np.mean(m, axis=0)
        data_collector[&#34;std_&#34; + key] = np.std(m, axis=0)
        data_collector[&#34;sem_&#34; + key] = stats.sem(m, axis=0)
        data_collector[&#34;m_&#34; + key] = m

    return data_collector


def concat_df(
    data_collector: DefaultDict, rounds: int
) -&gt; DefaultDict[str, Union[DefaultDict, List[Any]]]:
    &#34;&#34;&#34;Concates the different pandasDataFrame to one.

    Args:
        data_collector (DefaultDict): Contains all the data,each main key respresent the
                                        repetition number. In other words, the data is
                                        averaged over all the repetition.

    Returns:
        DefaultDict[Union[int, str], Union[DefaultDict, List[Any]]]:
                            Returns next to the data also the mean and float for each data
    &#34;&#34;&#34;
    # Get the number of repetition
    repetition = len([s for s in data_collector.keys() if s.isdigit()])

    # Check if the df is not empty
    if len(data_collector[&#34;0&#34;][&#34;df&#34;]) &gt; 0:
        list_of_dfs = []
        for i in range(0, repetition):
            list_of_dfs.append(data_collector[str(i)][&#34;df&#34;])
        df_total = pd.concat(list_of_dfs)
        data_collector[&#34;df_total&#34;] = df_total
        # divide the criminal_likelihood by the number of rounds
        data_collector[&#34;df_total&#34;][&#34;criminal_likelihood&#34;] = data_collector[&#34;df_total&#34;][
            &#34;criminal_likelihood&#34;
        ].div(rounds)

    return data_collector


def get_correlation(x: List[Union[float, int]], y: List[Union[float, int]]) -&gt; str:
    &#34;&#34;&#34;Get the correlation between x and y.&#34;&#34;&#34;
    # only look at the criminal_likelihood
    corr, p_val = pearsonr(x, y)

    p_star = &#34;&#34;.join([&#34;*&#34; for t in [0.01, 0.05, 0.1] if p_val &lt;= t])
    corr_with_p = corr.round(2).astype(str) + p_star
    return corr_with_p


def bootstrapping(data: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;Return a bootstrapping of the matrix data.

    Data needs to be a 2 dimensional matrix
    &#34;&#34;&#34;
    shuffle_array = deepcopy(data)

    if shuffle_array.shape[1] % 4 == 0:
        modulo = 4
    elif shuffle_array.shape[1] % 5 == 0:
        modulo = 5
    elif shuffle_array.shape[1] % 6 == 0:
        modulo = 6
    else:
        raise RuntimeError(&#34;Need to find/add modulo yourself!!&#34;)

    for row in range(0, shuffle_array.shape[0]):
        np.random.shuffle(shuffle_array[row, :].reshape((-1, modulo)))
    return shuffle_array


def compare_time_series(
    whole_data: DefaultDict[str, DefaultDict[str, Union[List[Any], np.ndarray]]]
) -&gt; None:
    &#34;&#34;&#34;Compare the time series by fitting a model and perform a anova-test on it.&#34;&#34;&#34;
    attachment_methods = list(whole_data.keys())
    attachment_methods_comb = list(itertools.combinations(attachment_methods, 2))
    metrics = [
        metric
        for metric in list(whole_data[attachment_methods[0]].keys())
        if metric.startswith(&#34;mean_&#34;)
        if &#34;fitness&#34; not in metric
        if &#34;ratio&#34; not in metric
    ]

    for metric in metrics:
        print(&#34;----&#34; + metric + &#34;----&#34;)
        for method in [&#34;pcm&#34;, &#34;frechet_dist&#34;, &#34;area_between_two_curves&#34;, &#34;dtw&#34;]:
            for comb in attachment_methods_comb:

                time_serie_a = np.zeros((len(whole_data[comb[0]][metric]), 2))
                time_serie_a[:, 0] = whole_data[comb[0]][metric]
                time_serie_a[:, 1] = whole_data[comb[0]][&#34;mean_iteration&#34;]

                time_serie_b = np.zeros((len(whole_data[comb[1]][metric]), 2))
                time_serie_b[:, 0] = whole_data[comb[1]][metric]
                time_serie_b[:, 1] = whole_data[comb[1]][&#34;mean_iteration&#34;]

                if method == &#34;pcm&#34;:
                    print(
                        f&#34;{str(comb):50} : {&#39;pcm&#39;:12} \
                        {similaritymeasures.pcm(time_serie_a,time_serie_b)}&#34;
                    )
                elif method == &#34;frechet_dist&#34;:
                    print(
                        f&#34;{str(comb):50} : {&#39;frechet_dist&#39;:12} \
                            {similaritymeasures.frechet_dist(time_serie_a,time_serie_b)}&#34;
                    )
                elif method == &#34;area_between_two_curves&#34;:
                    print(
                        f&#34;{str(comb):50} : {&#39;area&#39;:12} \
                            {similaritymeasures.area_between_two_curves(time_serie_a,time_serie_b)}&#34;
                    )
                elif method == &#34;dtw&#34;:
                    print(
                        f&#34;{str(comb):50} : {&#39;dtw&#39;:12} \
                            {similaritymeasures.dtw(time_serie_a,time_serie_b)[0]}&#34;
                    )

                # https://stats.stackexchange.com/questions/156864/comparing-2-sets-of-longitudinal-data
                series_1, series_2 = comb
                final_diff = []
                for i in range(0, 10000):
                    series_1_boot_samp_1 = bootstrapping(
                        data=whole_data[series_1][metric.replace(&#34;mean&#34;, &#34;m&#34;)]
                    )
                    series_1_boot_samp_2 = bootstrapping(
                        data=whole_data[series_1][metric.replace(&#34;mean&#34;, &#34;m&#34;)]
                    )

                    series_2_boot_samp_1 = bootstrapping(
                        data=whole_data[series_2][metric.replace(&#34;mean&#34;, &#34;m&#34;)]
                    )

                    # average aboslute differences
                    aad = np.abs(
                        np.mean(series_1_boot_samp_1) - np.mean(series_2_boot_samp_1)
                    )
                    var = np.abs(
                        np.mean(series_1_boot_samp_1) - np.mean(series_1_boot_samp_2)
                    )

                    # Final Diff&#34; can be interpreted to be the final difference between
                    # the AAD of series 1 and series 2 after accounting for natural
                    # variation in series 1.
                    final_diff.append(aad - var)

                print(
                    f&#34;Bootstrapping :  {str(comb):50}, value {np.percentile(final_diff, 1)}&#34;
                )

        print(30 * &#34;-&#34;)

        # stats f_oneway functions takes the groups as input and returns F and P-value
        fvalue, pvalue = stats.f_oneway(
            whole_data[&#34;preferential&#34;][metric.replace(&#34;mean&#34;, &#34;m&#34;)].flatten(),
            whole_data[&#34;random&#34;][metric.replace(&#34;mean&#34;, &#34;m&#34;)].flatten(),
            whole_data[&#34;small-world&#34;][metric.replace(&#34;mean&#34;, &#34;m&#34;)].flatten(),
        )
        print(
            f&#34;Results of ANOVA test:\nThe F-statistic is: {fvalue}\nThe p-value is: {pvalue}&#34;
        )

        df_pref = pd.DataFrame(
            {
                &#34;score&#34;: whole_data[&#34;preferential&#34;][
                    metric.replace(&#34;mean&#34;, &#34;m&#34;)
                ].flatten(),
                &#34;group&#34;: &#34;preferential&#34;,
            }
        )
        df_rand = pd.DataFrame(
            {
                &#34;score&#34;: whole_data[&#34;random&#34;][metric.replace(&#34;mean&#34;, &#34;m&#34;)].flatten(),
                &#34;group&#34;: &#34;random&#34;,
            }
        )
        df_sw = pd.DataFrame(
            {
                &#34;score&#34;: whole_data[&#34;small-world&#34;][
                    metric.replace(&#34;mean&#34;, &#34;m&#34;)
                ].flatten(),
                &#34;group&#34;: &#34;small-world&#34;,
            }
        )

        df = pd.concat([df_pref, df_rand, df_sw])
        # perform Tukey&#39;s test
        tukey = pairwise_tukeyhsd(endog=df[&#34;score&#34;], groups=df[&#34;group&#34;], alpha=0.05)
        print(tukey)
        print(&#34;\n&#34;)


def dict_mean(dict_list: Dict) -&gt; Dict[str, Union[int, float]]:
    &#34;&#34;&#34;Return an average/std value of a list of dictionaries.&#34;&#34;&#34;
    mean_dict = {}
    for key in dict_list[0].keys():
        mean_dict[key + &#34;_mean&#34;] = np.mean([d[key] for d in dict_list], axis=0)
        mean_dict[key + &#34;_std&#34;] = 1.96 * np.std([d[key] for d in dict_list], axis=0)

    return mean_dict</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="utils.stats.bootstrapping"><code class="name flex">
<span>def <span class="ident">bootstrapping</span></span>(<span>data:Â numpy.ndarray) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Return a bootstrapping of the matrix data.</p>
<p>Data needs to be a 2 dimensional matrix</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bootstrapping(data: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;Return a bootstrapping of the matrix data.

    Data needs to be a 2 dimensional matrix
    &#34;&#34;&#34;
    shuffle_array = deepcopy(data)

    if shuffle_array.shape[1] % 4 == 0:
        modulo = 4
    elif shuffle_array.shape[1] % 5 == 0:
        modulo = 5
    elif shuffle_array.shape[1] % 6 == 0:
        modulo = 6
    else:
        raise RuntimeError(&#34;Need to find/add modulo yourself!!&#34;)

    for row in range(0, shuffle_array.shape[0]):
        np.random.shuffle(shuffle_array[row, :].reshape((-1, modulo)))
    return shuffle_array</code></pre>
</details>
</dd>
<dt id="utils.stats.compare_time_series"><code class="name flex">
<span>def <span class="ident">compare_time_series</span></span>(<span>whole_data:Â DefaultDict[str,Â DefaultDict[str,Â Union[List[Any],Â numpy.ndarray]]]) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Compare the time series by fitting a model and perform a anova-test on it.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compare_time_series(
    whole_data: DefaultDict[str, DefaultDict[str, Union[List[Any], np.ndarray]]]
) -&gt; None:
    &#34;&#34;&#34;Compare the time series by fitting a model and perform a anova-test on it.&#34;&#34;&#34;
    attachment_methods = list(whole_data.keys())
    attachment_methods_comb = list(itertools.combinations(attachment_methods, 2))
    metrics = [
        metric
        for metric in list(whole_data[attachment_methods[0]].keys())
        if metric.startswith(&#34;mean_&#34;)
        if &#34;fitness&#34; not in metric
        if &#34;ratio&#34; not in metric
    ]

    for metric in metrics:
        print(&#34;----&#34; + metric + &#34;----&#34;)
        for method in [&#34;pcm&#34;, &#34;frechet_dist&#34;, &#34;area_between_two_curves&#34;, &#34;dtw&#34;]:
            for comb in attachment_methods_comb:

                time_serie_a = np.zeros((len(whole_data[comb[0]][metric]), 2))
                time_serie_a[:, 0] = whole_data[comb[0]][metric]
                time_serie_a[:, 1] = whole_data[comb[0]][&#34;mean_iteration&#34;]

                time_serie_b = np.zeros((len(whole_data[comb[1]][metric]), 2))
                time_serie_b[:, 0] = whole_data[comb[1]][metric]
                time_serie_b[:, 1] = whole_data[comb[1]][&#34;mean_iteration&#34;]

                if method == &#34;pcm&#34;:
                    print(
                        f&#34;{str(comb):50} : {&#39;pcm&#39;:12} \
                        {similaritymeasures.pcm(time_serie_a,time_serie_b)}&#34;
                    )
                elif method == &#34;frechet_dist&#34;:
                    print(
                        f&#34;{str(comb):50} : {&#39;frechet_dist&#39;:12} \
                            {similaritymeasures.frechet_dist(time_serie_a,time_serie_b)}&#34;
                    )
                elif method == &#34;area_between_two_curves&#34;:
                    print(
                        f&#34;{str(comb):50} : {&#39;area&#39;:12} \
                            {similaritymeasures.area_between_two_curves(time_serie_a,time_serie_b)}&#34;
                    )
                elif method == &#34;dtw&#34;:
                    print(
                        f&#34;{str(comb):50} : {&#39;dtw&#39;:12} \
                            {similaritymeasures.dtw(time_serie_a,time_serie_b)[0]}&#34;
                    )

                # https://stats.stackexchange.com/questions/156864/comparing-2-sets-of-longitudinal-data
                series_1, series_2 = comb
                final_diff = []
                for i in range(0, 10000):
                    series_1_boot_samp_1 = bootstrapping(
                        data=whole_data[series_1][metric.replace(&#34;mean&#34;, &#34;m&#34;)]
                    )
                    series_1_boot_samp_2 = bootstrapping(
                        data=whole_data[series_1][metric.replace(&#34;mean&#34;, &#34;m&#34;)]
                    )

                    series_2_boot_samp_1 = bootstrapping(
                        data=whole_data[series_2][metric.replace(&#34;mean&#34;, &#34;m&#34;)]
                    )

                    # average aboslute differences
                    aad = np.abs(
                        np.mean(series_1_boot_samp_1) - np.mean(series_2_boot_samp_1)
                    )
                    var = np.abs(
                        np.mean(series_1_boot_samp_1) - np.mean(series_1_boot_samp_2)
                    )

                    # Final Diff&#34; can be interpreted to be the final difference between
                    # the AAD of series 1 and series 2 after accounting for natural
                    # variation in series 1.
                    final_diff.append(aad - var)

                print(
                    f&#34;Bootstrapping :  {str(comb):50}, value {np.percentile(final_diff, 1)}&#34;
                )

        print(30 * &#34;-&#34;)

        # stats f_oneway functions takes the groups as input and returns F and P-value
        fvalue, pvalue = stats.f_oneway(
            whole_data[&#34;preferential&#34;][metric.replace(&#34;mean&#34;, &#34;m&#34;)].flatten(),
            whole_data[&#34;random&#34;][metric.replace(&#34;mean&#34;, &#34;m&#34;)].flatten(),
            whole_data[&#34;small-world&#34;][metric.replace(&#34;mean&#34;, &#34;m&#34;)].flatten(),
        )
        print(
            f&#34;Results of ANOVA test:\nThe F-statistic is: {fvalue}\nThe p-value is: {pvalue}&#34;
        )

        df_pref = pd.DataFrame(
            {
                &#34;score&#34;: whole_data[&#34;preferential&#34;][
                    metric.replace(&#34;mean&#34;, &#34;m&#34;)
                ].flatten(),
                &#34;group&#34;: &#34;preferential&#34;,
            }
        )
        df_rand = pd.DataFrame(
            {
                &#34;score&#34;: whole_data[&#34;random&#34;][metric.replace(&#34;mean&#34;, &#34;m&#34;)].flatten(),
                &#34;group&#34;: &#34;random&#34;,
            }
        )
        df_sw = pd.DataFrame(
            {
                &#34;score&#34;: whole_data[&#34;small-world&#34;][
                    metric.replace(&#34;mean&#34;, &#34;m&#34;)
                ].flatten(),
                &#34;group&#34;: &#34;small-world&#34;,
            }
        )

        df = pd.concat([df_pref, df_rand, df_sw])
        # perform Tukey&#39;s test
        tukey = pairwise_tukeyhsd(endog=df[&#34;score&#34;], groups=df[&#34;group&#34;], alpha=0.05)
        print(tukey)
        print(&#34;\n&#34;)</code></pre>
</details>
</dd>
<dt id="utils.stats.concat_df"><code class="name flex">
<span>def <span class="ident">concat_df</span></span>(<span>data_collector:Â DefaultDict[~KT,Â ~VT], rounds:Â int) â€‘>Â DefaultDict[str,Â Union[DefaultDict[~KT,Â ~VT],Â List[Any]]]</span>
</code></dt>
<dd>
<div class="desc"><p>Concates the different pandasDataFrame to one.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_collector</code></strong> :&ensp;<code>DefaultDict</code></dt>
<dd>Contains all the data,each main key respresent the
repetition number. In other words, the data is
averaged over all the repetition.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>DefaultDict[Union[int, str], Union[DefaultDict, List[Any]]]:
Returns next to the data also the mean and float for each data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def concat_df(
    data_collector: DefaultDict, rounds: int
) -&gt; DefaultDict[str, Union[DefaultDict, List[Any]]]:
    &#34;&#34;&#34;Concates the different pandasDataFrame to one.

    Args:
        data_collector (DefaultDict): Contains all the data,each main key respresent the
                                        repetition number. In other words, the data is
                                        averaged over all the repetition.

    Returns:
        DefaultDict[Union[int, str], Union[DefaultDict, List[Any]]]:
                            Returns next to the data also the mean and float for each data
    &#34;&#34;&#34;
    # Get the number of repetition
    repetition = len([s for s in data_collector.keys() if s.isdigit()])

    # Check if the df is not empty
    if len(data_collector[&#34;0&#34;][&#34;df&#34;]) &gt; 0:
        list_of_dfs = []
        for i in range(0, repetition):
            list_of_dfs.append(data_collector[str(i)][&#34;df&#34;])
        df_total = pd.concat(list_of_dfs)
        data_collector[&#34;df_total&#34;] = df_total
        # divide the criminal_likelihood by the number of rounds
        data_collector[&#34;df_total&#34;][&#34;criminal_likelihood&#34;] = data_collector[&#34;df_total&#34;][
            &#34;criminal_likelihood&#34;
        ].div(rounds)

    return data_collector</code></pre>
</details>
</dd>
<dt id="utils.stats.dict_mean"><code class="name flex">
<span>def <span class="ident">dict_mean</span></span>(<span>dict_list:Â Dict[~KT,Â ~VT]) â€‘>Â Dict[str,Â Union[int,Â float]]</span>
</code></dt>
<dd>
<div class="desc"><p>Return an average/std value of a list of dictionaries.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dict_mean(dict_list: Dict) -&gt; Dict[str, Union[int, float]]:
    &#34;&#34;&#34;Return an average/std value of a list of dictionaries.&#34;&#34;&#34;
    mean_dict = {}
    for key in dict_list[0].keys():
        mean_dict[key + &#34;_mean&#34;] = np.mean([d[key] for d in dict_list], axis=0)
        mean_dict[key + &#34;_std&#34;] = 1.96 * np.std([d[key] for d in dict_list], axis=0)

    return mean_dict</code></pre>
</details>
</dd>
<dt id="utils.stats.get_correlation"><code class="name flex">
<span>def <span class="ident">get_correlation</span></span>(<span>x:Â List[Union[float,Â int]], y:Â List[Union[float,Â int]]) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Get the correlation between x and y.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_correlation(x: List[Union[float, int]], y: List[Union[float, int]]) -&gt; str:
    &#34;&#34;&#34;Get the correlation between x and y.&#34;&#34;&#34;
    # only look at the criminal_likelihood
    corr, p_val = pearsonr(x, y)

    p_star = &#34;&#34;.join([&#34;*&#34; for t in [0.01, 0.05, 0.1] if p_val &lt;= t])
    corr_with_p = corr.round(2).astype(str) + p_star
    return corr_with_p</code></pre>
</details>
</dd>
<dt id="utils.stats.get_mean_std_over_list"><code class="name flex">
<span>def <span class="ident">get_mean_std_over_list</span></span>(<span>data_collector:Â DefaultDict[~KT,Â ~VT]) â€‘>Â DefaultDict[str,Â Union[DefaultDict[~KT,Â ~VT],Â List[Any]]]</span>
</code></dt>
<dd>
<div class="desc"><p>Take the average and st/sem over multiple lists from a defaultdict(list).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_collector</code></strong> :&ensp;<code>DefaultDict</code></dt>
<dd>Contains all the data,each main key respresent the
repetition number. In other words, the data is
averaged over all the repetition.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>DefaultDict[Union[int, str], Union[DefaultDict, List[Any]]]:
Returns next to the data also the mean and float for each data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mean_std_over_list(
    data_collector: DefaultDict,
) -&gt; DefaultDict[str, Union[DefaultDict, List[Any]]]:
    &#34;&#34;&#34;Take the average and st/sem over multiple lists from a defaultdict(list).

    Args:
        data_collector (DefaultDict): Contains all the data,each main key respresent the
                                        repetition number. In other words, the data is
                                        averaged over all the repetition.

    Returns:
        DefaultDict[Union[int, str], Union[DefaultDict, List[Any]]]:
                            Returns next to the data also the mean and float for each data
    &#34;&#34;&#34;
    try:
        for k in data_collector.keys():
            if k.isalpha():
                raise RuntimeError(
                    &#34;Sorry, only numeric keys allowed, for example: round &#39;0&#39;,&#39;1&#39;,&#39;2&#39;,...&#34;
                )
    except RuntimeError:
        print(&#34;Wrong keys were given to the function.&#34;)
        raise

    repetition = len([s for s in data_collector.keys() if s.isdigit()])
    keys = list(data_collector[&#34;0&#34;].keys())
    if &#34;df&#34; in keys:
        keys.remove(&#34;df&#34;)
    for key in keys:
        m = np.zeros((repetition, len(data_collector[&#34;0&#34;][key])))
        for i in range(0, repetition):
            # Matrix repetition x rounds
            m[i, :] = data_collector[str(i)][key]
        # Get mean and std
        data_collector[&#34;mean_&#34; + key] = np.mean(m, axis=0)
        data_collector[&#34;std_&#34; + key] = np.std(m, axis=0)
        data_collector[&#34;sem_&#34; + key] = stats.sem(m, axis=0)
        data_collector[&#34;m_&#34; + key] = m

    return data_collector</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="utils" href="index.html">utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="utils.stats.bootstrapping" href="#utils.stats.bootstrapping">bootstrapping</a></code></li>
<li><code><a title="utils.stats.compare_time_series" href="#utils.stats.compare_time_series">compare_time_series</a></code></li>
<li><code><a title="utils.stats.concat_df" href="#utils.stats.concat_df">concat_df</a></code></li>
<li><code><a title="utils.stats.dict_mean" href="#utils.stats.dict_mean">dict_mean</a></code></li>
<li><code><a title="utils.stats.get_correlation" href="#utils.stats.get_correlation">get_correlation</a></code></li>
<li><code><a title="utils.stats.get_mean_std_over_list" href="#utils.stats.get_mean_std_over_list">get_mean_std_over_list</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>
